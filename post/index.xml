<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>https://vchernoy.xyz/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Jul 2017 07:29:43 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Cracking Multivariate Recursive Equations Using Generating Functions</title>
      <link>https://vchernoy.xyz/post/two-var-recursive-func/</link>
      <pubDate>Tue, 04 Jul 2017 07:29:43 +0000</pubDate>
      
      <guid>https://vchernoy.xyz/post/two-var-recursive-func/</guid>
      <description>

&lt;p&gt;In this post, we consider a combinatorial problem.
It has a nice recursive solution, which could be implemented efficiently using Dynamic Programming technique.
Then using generating function, we find the closed formula, expressed with the binomial coefficients.
Finaly, we show that the closed formula gives us much faster way to compute the result than the the DP solution.&lt;/p&gt;

&lt;p&gt;Generating functions are usually applied to the case of single variable recursive function.
But actually, the technique may be extended to multivariate recursive functions, or even for a system of recursive functions.&lt;/p&gt;

&lt;p&gt;Sometimes the generating functions may give a fantastic result, and here we discuss one of such cases.&lt;/p&gt;

&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;We consider a problem that has a nice DP (Dynamic Programming) solution.
Similar questions might be asked on coding interviews or may be suggested as trivial problems on coding contests.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Compute the number of ways to choose m elements from n elements in a way that resulted elements are not adjacent.&lt;/p&gt;

&lt;p&gt;For example, $F_{4,2}=3$ since from the 4-elements set: $\lbrace 1,2,3,4 \rbrace$,
there are three feasible 2-elements combinations: $\lbrace 1,4 \rbrace$, $\lbrace 2,4 \rbrace$, $\lbrace 1,3 \rbrace$.
And $F_{5,3}=1$, since there is only one feasible 3-elements combination: $\lbrace 1,3,5 \rbrace$.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make recursive function for $ F_{n, m} $ by looking at $n$-th element. We can either:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Skip the $n$-th element, then $ F_{n, m} = F_{n-1, m} $.&lt;/li&gt;
&lt;li&gt;Pick the $n$-th element, then $ F_{n, m} = F_{n-2, m-1} $.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following recursive function: $ F_{n, m} = F_{n - 1, m} + F_{n - 2, m - 1} $,
with the corner cases: $F_{0, 0} = F_{1, 1} = 1$.&lt;/p&gt;

&lt;p&gt;The function $F$ has a straighforward recursive implementation in any programming language.
But the naive recursive solution will have exponential in $n$ time complexity and will be very slow.
Let&amp;rsquo;s look at the following &lt;code&gt;Python 3&lt;/code&gt; code snippet that uses memoization technique:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import functools
import sys

sys.setrecursionlimit(100000)

@functools.lru_cache(maxsize=None)
def f_mem(n, m):
    if n &amp;lt; 0 or m &amp;lt; 0:
        return 0

    if n + 1 &amp;lt; 2 * m:
        return 0

    if n == m == 0:
        return 1

    if n == m == 1:
        return 1

    return f_mem(n-1, m) + f_mem(n-2, m-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nice &lt;code&gt;@functools.lru_cache(maxsize=None)&lt;/code&gt; notation created a wrapper on the &lt;code&gt;f_mem&lt;/code&gt; function and internally caches results of all calls.
Such caching (or memoization) improves significantly the speed of the recursion, and basically reduces the number of calls to something like $n \cdot m$.
The recursion still may fail on the stack overflow even on relatively small values of $n$.
That is why we increase the stack size, which is easy to do in Python by calling &lt;code&gt;sys.setrecursionlimit()&lt;/code&gt;-method.&lt;/p&gt;

&lt;p&gt;The next implementation is iterative DP (Dynamic Programming).
Basically, it fills out the $n \times m$ table starting from the low values of $n$ and $m$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def f_dp(n, m):
    assert n &amp;gt;= 0 and m &amp;gt;= 0

    if n+1 &amp;lt; 2*m:
        return 0

    table = [[0] * (m+1) for _ in range(n+1)]

    table[0][0] = 1
    if n &amp;gt;= 1:
        table[1][0] = 1
        if m &amp;gt;= 1:
            table[1][1] = 1

    for i in range(2, n+1):
        table[i][0] = 1
        for j in range(1, min(m, (i + 1) // 2) + 1):
            table[i][j] = table[i-1][j] + table[i-2][j-1]

    return table[n][m]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The time and space complexities are $O(n\cdot m) $.
More accurate upper bound for the running time would be $O(n\cdot \min(n,m))$.
It is not hard to notice that the space consumption could be improved to $O(m)$.&lt;/p&gt;

&lt;h2 id=&#34;the-generating-function&#34;&gt;The Generating Function&lt;/h2&gt;

&lt;p&gt;The notion of generation function and its application for solving recursive equations are very well known.
Let&amp;rsquo;s consider how this works on the example of Fibonacci numbers.
Readers who are familiar with one-variable case may jump to the next section where we discuss how to apply the generation functions on $F_{n,m}$.&lt;/p&gt;

&lt;p&gt;For the Fibonacci numbers, defined by the recursion $f_n = f_{n-1} + f_{n-2} + [n=0]$.
We assume that for any $n &amp;lt; 0$, $f_n = 0$. The indicator $[n=0]$ equals to 1 only if $n=1$.
Together with the main case, starting from $n=0$, it produces the following sequence: 1, 1, 2, 3, 5, 8, 13, $\dots$.&lt;/p&gt;

&lt;p&gt;The generating function for $f_n$ is defined as an infinite sum of one variable $x$: $\Phi(x) = \sum_{n\geq 0} f_n\cdot x^n$.
Usually, it is hard to build an intuition why it is defined that way and why it could be useful.
So let&amp;rsquo;s just focuse on what we can do with this and we start from substituting the defintion of Fibonacci recursion into the formular of generation function:&lt;/p&gt;

&lt;p&gt;$$\Phi(x) = \sum_n f_n\cdot x^n = \sum_n (f_{n-1} + f_{n-2} + [n=0]) \cdot x^n $$&lt;/p&gt;

&lt;p&gt;$$ = \sum_n f_{n-1}\cdot x^n  + \sum_n f_{n-2}\cdot x^n  + \sum_n [n=0]\cdot x^n  $$&lt;/p&gt;

&lt;p&gt;$$ = x \cdot \sum_n f_{n-1}\cdot x^{n-1}  + x^2\cdot \sum_n f_{n-2}\cdot x^{n-2}  + 1\cdot x^0 $$&lt;/p&gt;

&lt;p&gt;$$ = x \cdot \sum_n f_n\cdot x^n  + x^2\cdot \sum_n f_n\cdot x^n  + 1 =  x \cdot \Phi(x) + x^2\cdot \Phi(x)  + 1 $$&lt;/p&gt;

&lt;p&gt;And we can obtain the generating function for $f_n$: $\Phi(x) = \frac{1}{1 - x - x^2}$.
Nice, but what can we do with this &amp;ldquo;magic&amp;rdquo; formula?
We can hack it in different ways, and depending on our next step, we can get different expression for $f_n$.&lt;/p&gt;

&lt;p&gt;One of the standard ways is to split the fraction into two simple ones of the form: $\frac{A}{B-x}$.
Note that the roots of the quadratic equation: $1 - x - x^2 = 0$ are $x_0=-\phi$ and $x_1=\phi^{-1}$, where $\phi$ is the &lt;em&gt;Goldan Ratio&lt;/em&gt;:
$\phi=\frac{1+\sqrt{5}}{2}=1.618\dots$.&lt;/p&gt;

&lt;p&gt;A quick test:
$ -(x-x_0)\cdot(x-x_1) = -(x+\phi)\cdot \left(x-\phi^{-1}\right) $
$ =-x^2 - x\cdot\left(\phi - \phi^{-1}\right) + 1 = -x^2 - x + 1 $.&lt;/p&gt;

&lt;p&gt;This results in $\Phi(x)=\frac{1}{1-x-x^2}$
$ = -\frac{1}{(x+\phi)\cdot\left(x-\phi^{-1}\right)}$
$ = \frac{A}{x+\phi} - \frac{A}{x-\phi^{-1}}$
$ = A\cdot\phi^{-1}\cdot(1+x/\phi) + A\cdot\phi\cdot(1 - x\cdot\phi)$,
where $A=\frac{1}{\phi+\phi^{-1}}$.&lt;/p&gt;

&lt;p&gt;We can apply the infinite series $\frac{1}{1-z} = \sum_n z^n$ for each expression and we will get:
$\Phi(x) = A\cdot\phi^{-1}\cdot \sum_n (-x/\phi)^n + A\cdot\phi\cdot \sum_n (x\cdot\phi)^n $
$ = A\cdot\phi^{-1}\cdot \sum_n (-\phi)^{-n}\cdot x^n + A\cdot\phi\cdot \sum_n \phi^n\cdot x^n $
$ = \sum_n \left(A\cdot\phi^{-1}\cdot(-\phi)^{-n} + A\cdot\phi\cdot \phi^n \right) \cdot x^n $
$ = \sum_n A\cdot\left(\phi^{n+1} - (-\phi)^{-n-1}\right) \cdot x^n $.&lt;/p&gt;

&lt;p&gt;The term before $x^n$ is nothing but $f_n$, which means that $f_n=\frac{\phi^{n+1} - (-\phi)^{-n-1}}{\phi+\phi^{-1}}$.&lt;/p&gt;

&lt;p&gt;Another way to crack the generating function is to apply the infinite series $\frac{1}{1-z} = \sum_n z^n$ directly to the fraction:
$\Phi(x) = \frac{1}{1 - x - x^2} $
$ = \frac{1}{1 - (x+x^2)}$
$ = \sum_n (x+x^2)^n $
$ = \sum_n (1+x)^n\cdot x^n $
$ = \sum_{0\leq k \leq n} {n \choose k}\cdot x^{n+k} $&lt;/p&gt;

&lt;p&gt;Introducing the new variable $t=n+k$, we obtain
$ = \sum_{t/2 \leq n \leq t} {n \choose t-n}\cdot x^t $
$ = \sum_t \sum_{n=t/2}^t {n \choose t-n}\cdot x^t $&lt;/p&gt;

&lt;p&gt;So we receive another closed form for the fibonacci numbers: $f_t = \sum_{n=t/2}^t {n \choose t-n}$.&lt;/p&gt;

&lt;p&gt;Can you believe that both forms define the same well known fibonacci series?&lt;/p&gt;

&lt;p&gt;$$ f_n=\frac{\phi^{n+1} - (-\phi)^{-n-1}}{\phi+\phi^{-1}} $$&lt;/p&gt;

&lt;p&gt;$$ f_n = \sum_{i=n/2}^t {i \choose n-i} $$&lt;/p&gt;

&lt;p&gt;Actually, the equations have been discovered many times ago, an interested reader may find other proofs showing the truth of the relations.
We just notice how powerful the generating functions might be and we will use them for two variable recursive functions.&lt;/p&gt;

&lt;h1 id=&#34;the-generating-function-for-f-n-m&#34;&gt;The Generating Function for $F_{n,m}$&lt;/h1&gt;

&lt;p&gt;We continue our analysis of the two variable recursion function:  $F_{n,m} = F_{n-1,m} + F_{n-2,m-1} + [n=m=0] + [n=m=1]$.
Let&amp;rsquo;s introduce the generating function $\Phi(x,y)$ of two (floating point) variables $x$ and $y$: $\Phi(x,y) = \sum_{n,m} F_{n,m}\cdot x^n y^m$.
Substituting the definition of $F_{n,m}$ and simplifying the sums, we will get:
$ \Phi(x,y) $
$ = \sum_{n,m} F_{n,m}\cdot x^n y^m $
$ = \sum_{n,m} \left(F_{n - 1, m} + F_{n - 2, m - 1} + [n=m=1] + [n=m=0] \right)\cdot x^n y^m$
$ = \sum_{n,m} F_{n - 1, m} \cdot x^n y^m  + \sum_{n,m} F_{n - 2, m - 1} \cdot x^n y^m + x \cdot y + 1 $
$ = x\cdot\sum_{n,m} F_{n - 1, m} \cdot x^{n-1} y^m + x^2y\cdot\sum_{n,m} F_{n - 2, m - 1} \cdot x^{n-2} y^{m-1} + x \cdot y + 1 $
$ = x\cdot \Phi(x,y)  + x^2y\cdot \Phi(x,y) + x \cdot y + 1 $&lt;/p&gt;

&lt;p&gt;Now we find the simple representation: $\Phi(x, y) = \frac{1 + x \cdot y}{1 - x - x^2 \cdot y}$.
We can convert it to an infinite series, using: $ \frac{1}{1-z} = \sum_{k\geq 0} z^k $:
$\Phi(x, y) $
$ = \frac{1 + x \cdot y}{1 - x - x^2 \cdot y}$
$ = (1 + x \cdot y) \cdot \sum_{k\geq 0} (x+x^2\cdot y)^k  $
$ = (1 + x \cdot y) \cdot \sum_{0 \leq i \leq k} {k \choose i} \cdot x^{k+i} \cdot y^i $&lt;/p&gt;

&lt;p&gt;Introduce $n=k+i, m=i$, then
$\Phi(x, y) $
$ = \sum_{0 \leq i \leq k} {k \choose i} \cdot x^{k+i} \cdot y^i $
$ = \sum_{m \geq 0, n \geq 2m} {n-m \choose m} \cdot x^{n} \cdot y^m $&lt;/p&gt;

&lt;p&gt;Introduce $n=k+i+1, m=i+1$, then
$\Phi(x, y) $
$ = x\cdot y \cdot \sum_{0 \leq i \leq k} {k \choose i} \cdot x^{k+i} \cdot y^i $
$ = \sum_{0 \leq i \leq k} {k \choose i} \cdot x^{k+i+1} \cdot y^{i+1} $
$ = \sum_{m \geq 1, n \geq 2m-1} {n-m \choose m-1} \cdot x^n \cdot y^m $&lt;/p&gt;

&lt;p&gt;The last two transformations give us the closed form: $F_{n, m} = {n - m \choose m} + {n - m \choose m - 1}$.
Which actually equals to $F_{n, m} = {n - m + 1 \choose m}$.&lt;/p&gt;

&lt;p&gt;Now we can reflect this idea very trivial Python code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import math

def f_binom(n, m):
    assert n &amp;gt;= 0 and m &amp;gt;= 0

    return binom(n-m+1, m) if n+1 &amp;gt;= 2*m else 0

def binom(n, m):
    assert 0 &amp;lt;= m &amp;lt;= n

    return math.factorial(n) // math.factorial(m) // math.factorial(n-m)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This implementation overperforms significantly the initial DP and memoization solutions.
A naive implementation of &lt;code&gt;math.factorial()&lt;/code&gt; could be linear in $n$, which still might be faster than DP approach.
Actually, the actual implementation is much more advance, it is written in C and caches values for a small range of the argument.&lt;/p&gt;

&lt;h2 id=&#34;faster-implementations-using-scipy-and-sympy&#34;&gt;Faster Implementations Using &lt;code&gt;scipy&lt;/code&gt; and &lt;code&gt;sympy&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;More promissing implementation for computing binomial coeffitients could be found the 3rd party libraries, let&amp;rsquo;s take a look at &lt;code&gt;scipy.special.comb()&lt;/code&gt; and &lt;code&gt;sympy.binomial()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import scipy.special

def f_sci(n, m):
    assert n &amp;gt;= 0 and m &amp;gt;= 0

    return scipy.special.comb(n-m+1, m, exact=True) if n+1 &amp;gt;= 2*m else 0

import sympy

def f_sym(n, m):
    assert n &amp;gt;= 0 and m &amp;gt;= 0

    return sympy.binomial(n-m+1, m) if n+1 &amp;gt;= 2*m else 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can easily install both by running:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install scipy sympy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to measure the time and check the correctness, let&amp;rsquo;s use the following helper function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import timeit

M=1000000007

def test(n, m, funcs, number=1, module=__name__, M=M):
    f_mem.cache_clear()
    results = []
    func_times = []
    for func in funcs:
        stmt=&#39;{}({},{})&#39;.format(func.__name__, n, m)
        setup=&#39;from {} import {}&#39;.format(module, func.__name__)
        t = timeit.timeit(stmt=stmt, setup=setup, number=number)
        func_times.append(t)
        results.append(func(n, m) % M)

    assert len(set(results)) &amp;lt;= 1

    if results:
        print(&#39;f({},{}): {}&#39;.format(n, m, results[0]))

    best_time = min(func_times)
    for i, func in enumerate(funcs):
        func_time = func_times[i]
        print(&#39;{:&amp;gt;8}: {:8.4f} sec, x {:.2f}&#39;.format(func.__name__, func_time, func_time/best_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can run it as following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;funcs = [f_mem, f_dp, f_binom, f_sci, f_sym]
test(6000, 2000, funcs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which prints the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;f(6000,2000): 192496093
   f_mem:   6.7195 sec, x 4195.10
    f_dp:   5.3249 sec, x 3324.43
 f_binom:   0.0016 sec, x 1.00
   f_sci:   0.0021 sec, x 1.32
   f_sym:   0.0043 sec, x 2.69
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function &lt;code&gt;test()&lt;/code&gt; computes $F_{6000, 2000}$ using five different ways.
It validates that all the solutions are consistent and produce the same result.
It also measures the time it takes to execute each method.
For each run, it also prints the relative factor computed based on the fastest case.
The function&amp;rsquo;s result is printed modulo $M$.&lt;/p&gt;

&lt;p&gt;This is not a surprise that the first two methods (memoization and DP) are much slower than the other three, which are based on the binomial coefficients.
Memoization and DP techniques have $Theta(n \cdot m) time complexity.
The &lt;code&gt;f_binom&lt;/code&gt;-method uses $factorial$ as a subroutine, which is linear in $n$ implemented in a naive way.
Note that we ignore here a lot of interesting details, for example, Python has builtin integer long arithmetics, which is used here and definetely not cheap.
Also &lt;code&gt;factorial&lt;/code&gt;-function may use memoization for storing its value.
Other methods based on &lt;code&gt;sympy&lt;/code&gt; and &lt;code&gt;scipy.special&lt;/code&gt;, may (and actually do) use memoization as well.
The impact of C-impementation is also out of scope of the current discassion as well as some other hard-core optimizations that one can apply.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s run the fastest algorithms on the different values of $m$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;test(6000,  500, funcs[2:])
test(6000, 1000, funcs[2:])
test(6000, 1500, funcs[2:])
test(6000, 2000, funcs[2:])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We may notice that there is no clear winner between the algorthms. It seems that &lt;code&gt;f_sym&lt;/code&gt; runs slower but for $F_{n, m} the range is pretty small, probably most of the time is spent on the long arithmetic computation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;f(6000,500): 940876663
 f_binom:   0.0038 sec, x 12.15
   f_sci:   0.0003 sec, x 1.00
   f_sym:   0.0046 sec, x 14.79

f(6000,1000): 491957471
 f_binom:   0.0025 sec, x 3.70
   f_sci:   0.0007 sec, x 1.00
   f_sym:   0.0037 sec, x 5.48

f(6000,1500): 325152517
 f_binom:   0.0019 sec, x 1.48
   f_sci:   0.0013 sec, x 1.00
   f_sym:   0.0035 sec, x 2.67

f(6000,2000): 192496093
 f_binom:   0.0016 sec, x 1.00
   f_sci:   0.0024 sec, x 1.49
   f_sym:   0.0033 sec, x 2.06
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
